/**
 * Composant d'import de recette par voix ou texte
 * Utilise Web Speech API pour la reconnaissance vocale
 */

"use client";

import React, { useState, useEffect, useRef } from "react";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";
import { Mic, MicOff, Loader2, Wand2, AlertCircle } from "lucide-react";
import { toast } from "sonner";

interface VoiceToTextImportProps {
  onClose: () => void;
  onRecipeGenerated: (recipe: any) => void;
  setIsImporting?: (value: boolean) => void;
  setImportPlatform?: (value: "youtube" | "tiktok" | null) => void;
  setImportStep?: (value: string | null) => void;
}

export function VoiceToTextImport({
  onClose,
  onRecipeGenerated,
  setIsImporting,
  setImportPlatform,
  setImportStep,
}: VoiceToTextImportProps) {
  const [text, setText] = useState("");
  const [isListening, setIsListening] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [isSupported, setIsSupported] = useState(true);
  const recognitionRef = useRef<any>(null);

  useEffect(() => {
    // V√©rifier si Web Speech API est support√©e
    if (typeof window !== 'undefined') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      if (!SpeechRecognition) {
        setIsSupported(false);
        toast.error("Micro non support√©", {
          description: "Votre navigateur ne supporte pas la reconnaissance vocale. Utilisez Chrome, Edge ou Safari.",
          icon: <AlertCircle className="h-5 w-5" />,
          duration: 6000,
        });
      }
    }

    return () => {
      // Cleanup : arr√™ter la reconnaissance si le composant est d√©mont√©
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  const startListening = async () => {
    if (!isSupported) {
      console.log('[Voice] Navigateur non support√©');
      return;
    }

    console.log('[Voice] D√©marrage de la reconnaissance vocale...');

    // Arr√™ter toute reconnaissance en cours
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }

    try {
      // √âtape 1: Demander explicitement la permission micro AVANT de d√©marrer la reconnaissance
      console.log('[Voice] üìã Demande de permission micro...');
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('[Voice] ‚úÖ Permission micro accord√©e');
        // Arr√™ter imm√©diatement le stream car on ne l'utilise que pour la permission
        stream.getTracks().forEach(track => track.stop());
      } catch (permError: any) {
        console.error('[Voice] ‚ùå Permission refus√©e:', permError);
        toast.error("Permission micro requise", {
          description: "Cliquez sur 'Autoriser' pour utiliser le micro.",
          icon: <MicOff className="h-5 w-5" />,
          duration: 6000,
        });
        return;
      }

      // √âtape 2: Cr√©er et configurer la reconnaissance vocale
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();

      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'fr-FR';

      console.log('[Voice] Configuration:', {
        continuous: recognition.continuous,
        interimResults: recognition.interimResults,
        lang: recognition.lang
      });

      recognition.onstart = () => {
        console.log('[Voice] ‚úÖ Reconnaissance d√©marr√©e');
        setIsListening(true);
      };

      recognition.onresult = (event: any) => {
        let finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript + ' ';
          }
        }

        if (finalTranscript) {
          setText(prev => prev + finalTranscript);
        }
      };

      recognition.onerror = (event: any) => {
        console.error('[Voice] ‚ùå Erreur:', {
          error: event.error,
          message: event.message,
          type: event.type
        });

        if (event.error === 'no-speech') {
          toast.error("Aucune parole d√©tect√©e", {
            description: "Parlez plus fort ou rapprochez-vous du micro.",
            icon: <Mic className="h-5 w-5" />,
            duration: 5000,
          });
        } else if (event.error === 'aborted') {
          console.log('[Voice] Arr√™t volontaire');
          // Pas de toast
        } else if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
          console.error('[Voice] Permission refus√©e ou service non autoris√©');
          toast.error("Acc√®s micro refus√©", {
            description: "Cliquez sur l'ic√¥ne üîí dans la barre d'adresse et autorisez le micro.",
            icon: <MicOff className="h-5 w-5" />,
            duration: 8000,
          });
        } else if (event.error === 'audio-capture') {
          toast.error("Micro introuvable", {
            description: "V√©rifiez qu'un micro est branch√© et s√©lectionn√©.",
            icon: <MicOff className="h-5 w-5" />,
            duration: 6000,
          });
        } else if (event.error === 'network') {
          toast.error("Erreur r√©seau", {
            description: "La reconnaissance vocale n√©cessite une connexion internet.",
            icon: <AlertCircle className="h-5 w-5" />,
            duration: 5000,
          });
        } else {
          toast.error("Erreur de reconnaissance vocale", {
            description: `${event.error || "Erreur inconnue"}. Rechargez la page et r√©essayez.`,
            icon: <AlertCircle className="h-5 w-5" />,
            duration: 6000,
          });
        }
        setIsListening(false);
      };

      recognition.onend = () => {
        console.log('[Voice] üõë Reconnaissance termin√©e');
        setIsListening(false);
      };

      console.log('[Voice] üé§ Lancement de recognition.start()...');
      recognition.start();
      recognitionRef.current = recognition;
      console.log('[Voice] ‚úÖ recognition.start() appel√© avec succ√®s');
    } catch (err) {
      console.error('[Voice] ‚ùå Erreur lors du d√©marrage:', err);
      toast.error("Erreur de d√©marrage", {
        description: "Impossible de d√©marrer la reconnaissance vocale. Rechargez la page.",
        icon: <AlertCircle className="h-5 w-5" />,
        duration: 5000,
      });
      setIsListening(false);
    }
  };

  const stopListening = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }
    setIsListening(false);
  };

  const handleGenerate = async () => {
    if (!text.trim()) {
      toast.error("Texte manquant", {
        description: "Veuillez entrer ou dicter du texte avant de g√©n√©rer la recette.",
        icon: <AlertCircle className="h-5 w-5" />,
        duration: 4000,
      });
      return;
    }

    setIsLoading(true);

    // Activer l'overlay de chargement
    setIsImporting?.(true);
    setImportPlatform?.(null);
    setImportStep?.("Analyse du texte avec l'IA...");

    try {
      // G√©n√©rer la recette avec ChatGPT
      const recipeRes = await fetch("/api/youtube/generate-recipe", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          title: "Recette dict√©e",
          description: "",
          transcript: text,
          videoUrl: "",
          imageUrl: "",
          author: "Dict√©e vocale",
        }),
      });

      if (!recipeRes.ok) {
        const data = await recipeRes.json();
        throw new Error(data.error || "Erreur lors de la g√©n√©ration de la recette");
      }

      const recipeData = await recipeRes.json();

      setImportStep?.("Finalisation...");

      // Petit d√©lai pour que l'utilisateur voie "Finalisation"
      await new Promise(resolve => setTimeout(resolve, 500));

      onRecipeGenerated(recipeData.recipe);

      setText("");
      onClose();

      // D√©sactiver le loading apr√®s un court d√©lai
      setTimeout(() => {
        setIsImporting?.(false);
        setImportPlatform?.(null);
        setImportStep?.(null);
      }, 300);
    } catch (err) {
      console.error("Erreur g√©n√©ration:", err);
      const errorMessage = err instanceof Error ? err.message : "Une erreur est survenue";
      toast.error("Erreur de g√©n√©ration", {
        description: errorMessage,
        icon: <AlertCircle className="h-5 w-5" />,
        duration: 5000,
      });
      // D√©sactiver le loading en cas d'erreur
      setIsImporting?.(false);
      setImportPlatform?.(null);
      setImportStep?.(null);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="mt-4 pt-4 border-t border-white/20 space-y-3">
      {/* Zone de texte compacte avec indicateur d'√©coute */}
      <div className="relative">
        <Textarea
          value={text}
          onChange={(e) => setText(e.target.value)}
          placeholder="Tapez ou dictez votre recette... Ex: 'P√¢tes carbonara : 200g p√¢tes, 100g lardons, 2 ≈ìufs...'"
          className="h-[150px] text-sm bg-white/90 dark:bg-stone-900 placeholder:text-stone-400 dark:placeholder:text-stone-500 text-stone-900 dark:text-white border border-stone-300 dark:border-stone-600 resize-none overflow-y-auto"
          disabled={isLoading}
        />
        {isListening && (
          <div className="absolute top-2 right-2 flex items-center gap-1.5 bg-red-500 text-white px-2 py-0.5 rounded-full text-xs font-medium animate-pulse">
            <div className="w-1.5 h-1.5 bg-white rounded-full animate-ping"></div>
            √âcoute...
          </div>
        )}
        {/* Compteur de caract√®res */}
        {text && (
          <div className="absolute bottom-1 right-2">
            <span className="text-[10px] text-stone-400 dark:text-stone-500">
              {text.length} car.
            </span>
          </div>
        )}
      </div>

      {/* Boutons d'action : G√©n√©rer √† gauche, Micro √† droite */}
      <div className="flex gap-2">
        {/* Bouton G√©n√©rer */}
        <Button
          onClick={handleGenerate}
          disabled={!text.trim() || isLoading || isListening}
          className="flex-1 bg-gradient-to-r from-emerald-600 to-green-600 hover:from-emerald-700 hover:to-green-700 text-white h-10 px-4 gap-2 font-medium"
        >
          {isLoading ? (
            <>
              <Loader2 className="h-4 w-4 animate-spin" />
              <span>G√©n√©ration...</span>
            </>
          ) : (
            <>
              <Wand2 className="h-4 w-4" />
              <span>G√©n√©rer la recette</span>
            </>
          )}
        </Button>

        {/* Bouton Micro */}
        {isSupported && (
          <Button
            type="button"
            onClick={isListening ? stopListening : startListening}
            disabled={isLoading}
            className={`h-10 px-4 gap-2 font-medium transition-all ${
              isListening
                ? "bg-red-600 hover:bg-red-700 text-white"
                : "bg-white hover:bg-stone-50 text-stone-700 border border-stone-300 dark:bg-stone-800 dark:hover:bg-stone-700 dark:text-white dark:border-stone-600"
            }`}
          >
            {isListening ? (
              <>
                <MicOff className="h-4 w-4" />
                <span>Stop</span>
              </>
            ) : (
              <>
                <Mic className="h-4 w-4" />
                <span>Micro</span>
              </>
            )}
          </Button>
        )}
      </div>
    </div>
  );
}
